{"version":3,"sources":["webpack:///path---blog-better-transformations-6292d2cb6fae5d5bf46d.js","webpack:///./.cache/json/blog-better-transformations.json"],"names":["webpackJsonp","423","module","exports","data","markdownRemark","html","timeToRead","excerpt","frontmatter","title","cover","date","category","tags","fields","slug","pathContext"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SACAC,MACAC,gBACAC,KAAA,80IACAC,WAAA,EACAC,QAAA,4IACAC,aACAC,MAAA,yBACAC,MAAA,uBACAC,KAAA,2BACAC,SAAA,OACAC,MACA,cACA,KACA,aACA,yBAGAC,QACAC,KAAA,kCAIAC,aACAD,KAAA","file":"path---blog-better-transformations-6292d2cb6fae5d5bf46d.js","sourcesContent":["webpackJsonp([87632488690416],{\n\n/***/ 423:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\n\t\t\"data\": {\n\t\t\t\"markdownRemark\": {\n\t\t\t\t\"html\": \"<p>As we’ve been adding skills to Optic (yes that’s the new name for Optic Knowledge), we’ve found ourself playing critical feature whack-a-mole. We definitely underestimated the number of critical use cases to get some of the everyday libraries and SDKs developers love supported. The good news is we’re just about there.</p>\\n<p>As reported last week we’ve already added support this month for:</p>\\n<ul>\\n<li>\\n<p>Mutating transformations — transformations that change existing code. Supports things like “Add Action to Reducer” for Redux</p>\\n</li>\\n<li>\\n<p>Multi transformation — transform one kind of code into multiple other types of code. Supports transformations that need to write to multiple files.</p>\\n</li>\\n</ul>\\n<p>This week we finished what we believe are the last core engines needed for a while:</p>\\n<ul>\\n<li>\\n<p>Insert locations — allows you to create new files as part of a transformation.</p>\\n</li>\\n<li>\\n<p>Parser proxies — enables lenses to be created with otherwise invalid source code. For instance putting a Case statement in the top level of a code snippet won’t parse. Parser proxies allow parser authors to define a wrapper on a per AST Type basis to overcome this limitation. End users won’t have to think about these but they are important.</p>\\n</li>\\n<li>\\n<p>Multi Node Lenses — allows you to create a lens composed of n number of AST Nodes. User cases include creating a lens for Redux Containers. Each with a Component, PropTypes, MapStateToProps, Connect and Export node. Multi Node lenses behave like any other lens and can be synced.</p>\\n</li>\\n<li>\\n<p>Sublime support added. Ajay Patel from <a href=\\\"https://www.plasticity.ai\\\">Plasticity</a> finished the plugin. We’ll be packaging this in the next version of the installer.</p>\\n</li>\\n</ul>\\n<h3 id=\\\"whats-next\\\"><a href=\\\"#whats-next\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>What’s Next</h3>\\n<p>This next release is already very big and contained a lot of risky features. It’s nearly ready to go but we’re going to delay it a little longer.</p>\\n<p>We want to switch our focus for the remainder of the summer from new features to building Optic’s repository of skills. To help with this task we feel like we have to make sure Optic Markdown 2 is part of this release.</p>\\n<p>Optic Markdown 2 is going to make it easier than ever to teach Optic new skills. It’s designed around the premise that Training > Explaining. Right now Optic Markdown is very verbose and requires users to fully grasp our system before they can make anything useful. V2 deploys some of the code pattern matching tech that makes Optic work to that training process.</p>\\n<p>In v1 users created lenses by giving a example snippet and then defining extractors to read/write certain properties of from that code. In v2 you provide a sample snippet and the expected JSON model to describe the code. Optic will search sample space and figure out how to round trip the code. If there are ambiguities that need resolution Optic will ask questions to resolve them and advanced users will still be able to override Optic’s decisions when needed.</p>\\n<p>It’s really cool and I’ve already seen some first time Optic users take advantage of the system without any coaching.</p>\\n<h2 id=\\\"thanks-for-supporting-optic-we-hope-youre-ready-for-the-big-release\\\"><a href=\\\"#thanks-for-supporting-optic-we-hope-youre-ready-for-the-big-release\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Thanks for supporting Optic! We hope you’re ready for the big release.</h2>\",\n\t\t\t\t\"timeToRead\": 2,\n\t\t\t\t\"excerpt\": \"As we’ve been adding skills to Optic (yes that’s the new name for Optic Knowledge), we’ve found ourself playing critical feature whack-a…\",\n\t\t\t\t\"frontmatter\": {\n\t\t\t\t\t\"title\": \"Better Transformations\",\n\t\t\t\t\t\"cover\": \"logos/optic-logo.png\",\n\t\t\t\t\t\"date\": \"2018-06-16T00:00:00.000Z\",\n\t\t\t\t\t\"category\": \"tech\",\n\t\t\t\t\t\"tags\": [\n\t\t\t\t\t\t\"programming\",\n\t\t\t\t\t\t\"ai\",\n\t\t\t\t\t\t\"automation\",\n\t\t\t\t\t\t\"software development\"\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"fields\": {\n\t\t\t\t\t\"slug\": \"/blog/better-transformations\"\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t\"pathContext\": {\n\t\t\t\"slug\": \"/blog/better-transformations\"\n\t\t}\n\t};\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---blog-better-transformations-6292d2cb6fae5d5bf46d.js","module.exports = {\n\t\"data\": {\n\t\t\"markdownRemark\": {\n\t\t\t\"html\": \"<p>As we’ve been adding skills to Optic (yes that’s the new name for Optic Knowledge), we’ve found ourself playing critical feature whack-a-mole. We definitely underestimated the number of critical use cases to get some of the everyday libraries and SDKs developers love supported. The good news is we’re just about there.</p>\\n<p>As reported last week we’ve already added support this month for:</p>\\n<ul>\\n<li>\\n<p>Mutating transformations — transformations that change existing code. Supports things like “Add Action to Reducer” for Redux</p>\\n</li>\\n<li>\\n<p>Multi transformation — transform one kind of code into multiple other types of code. Supports transformations that need to write to multiple files.</p>\\n</li>\\n</ul>\\n<p>This week we finished what we believe are the last core engines needed for a while:</p>\\n<ul>\\n<li>\\n<p>Insert locations — allows you to create new files as part of a transformation.</p>\\n</li>\\n<li>\\n<p>Parser proxies — enables lenses to be created with otherwise invalid source code. For instance putting a Case statement in the top level of a code snippet won’t parse. Parser proxies allow parser authors to define a wrapper on a per AST Type basis to overcome this limitation. End users won’t have to think about these but they are important.</p>\\n</li>\\n<li>\\n<p>Multi Node Lenses — allows you to create a lens composed of n number of AST Nodes. User cases include creating a lens for Redux Containers. Each with a Component, PropTypes, MapStateToProps, Connect and Export node. Multi Node lenses behave like any other lens and can be synced.</p>\\n</li>\\n<li>\\n<p>Sublime support added. Ajay Patel from <a href=\\\"https://www.plasticity.ai\\\">Plasticity</a> finished the plugin. We’ll be packaging this in the next version of the installer.</p>\\n</li>\\n</ul>\\n<h3 id=\\\"whats-next\\\"><a href=\\\"#whats-next\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>What’s Next</h3>\\n<p>This next release is already very big and contained a lot of risky features. It’s nearly ready to go but we’re going to delay it a little longer.</p>\\n<p>We want to switch our focus for the remainder of the summer from new features to building Optic’s repository of skills. To help with this task we feel like we have to make sure Optic Markdown 2 is part of this release.</p>\\n<p>Optic Markdown 2 is going to make it easier than ever to teach Optic new skills. It’s designed around the premise that Training > Explaining. Right now Optic Markdown is very verbose and requires users to fully grasp our system before they can make anything useful. V2 deploys some of the code pattern matching tech that makes Optic work to that training process.</p>\\n<p>In v1 users created lenses by giving a example snippet and then defining extractors to read/write certain properties of from that code. In v2 you provide a sample snippet and the expected JSON model to describe the code. Optic will search sample space and figure out how to round trip the code. If there are ambiguities that need resolution Optic will ask questions to resolve them and advanced users will still be able to override Optic’s decisions when needed.</p>\\n<p>It’s really cool and I’ve already seen some first time Optic users take advantage of the system without any coaching.</p>\\n<h2 id=\\\"thanks-for-supporting-optic-we-hope-youre-ready-for-the-big-release\\\"><a href=\\\"#thanks-for-supporting-optic-we-hope-youre-ready-for-the-big-release\\\" aria-hidden=\\\"true\\\" class=\\\"anchor\\\"><svg aria-hidden=\\\"true\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg></a>Thanks for supporting Optic! We hope you’re ready for the big release.</h2>\",\n\t\t\t\"timeToRead\": 2,\n\t\t\t\"excerpt\": \"As we’ve been adding skills to Optic (yes that’s the new name for Optic Knowledge), we’ve found ourself playing critical feature whack-a…\",\n\t\t\t\"frontmatter\": {\n\t\t\t\t\"title\": \"Better Transformations\",\n\t\t\t\t\"cover\": \"logos/optic-logo.png\",\n\t\t\t\t\"date\": \"2018-06-16T00:00:00.000Z\",\n\t\t\t\t\"category\": \"tech\",\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"programming\",\n\t\t\t\t\t\"ai\",\n\t\t\t\t\t\"automation\",\n\t\t\t\t\t\"software development\"\n\t\t\t\t]\n\t\t\t},\n\t\t\t\"fields\": {\n\t\t\t\t\"slug\": \"/blog/better-transformations\"\n\t\t\t}\n\t\t}\n\t},\n\t\"pathContext\": {\n\t\t\"slug\": \"/blog/better-transformations\"\n\t}\n};\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/blog-better-transformations.json\n// module id = 423\n// module chunks = 87632488690416"],"sourceRoot":""}